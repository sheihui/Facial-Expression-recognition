import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import DataLoader
from torchvision import transforms
from torch.backends import cudnn
from torch.cuda.amp import autocast  # 4090æ··åˆç²¾åº¦åŠ é€Ÿ

# å¯¼å…¥ä½ çš„è‡ªå®šä¹‰æ¨¡å—
from fer import Fer2013  # ä½ çš„FER2013 Datasetç±»
from models.resnet import ResNet18  # è®­ç»ƒå¥½çš„ResNet18ï¼ˆå¸¦Dropoutï¼‰
# å¦‚æœè¦æµ‹è¯•VGG19ï¼Œå–æ¶ˆæ³¨é‡Š
from models.vgg import VGG19

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰ =====================
# 1. è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆæ›¿æ¢ä¸ºä½ çš„resnet_original.pthï¼‰
# MODEL_WEIGHT_PATH = "./weights/resnet_original.pth"
MODEL_WEIGHT_PATH = "./weights/emotion_model.pth"
# 2. FER2013æ•°æ®è·¯å¾„ï¼ˆå›ºå®šä¸ºä½ æä¾›çš„./data/fer2013.h5ï¼‰
FER_H5_PATH = "./data/fer2013.h5"
# 3. æµ‹è¯•é›†ç±»å‹ï¼š"test"ï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰æˆ– "train"ï¼ˆæ‹Ÿåˆèƒ½åŠ›ï¼‰
TEST_SPLIT = "test"
# 4. è®¾å¤‡é…ç½®ï¼ˆä¼˜å…ˆ5090 GPUï¼‰
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# 5. è¶…å‚æ•°ï¼ˆå’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
BATCH_SIZE = 128
NUM_CLASSES = 7
# 6. è¡¨æƒ…æ ‡ç­¾æ˜ å°„ï¼ˆå®Œå…¨åŒ¹é…ä½ æä¾›çš„EMOTION_MAPï¼‰
EMOTION_MAP = {
    0: "angry",
    1: "disgust",
    2: "fear",
    3: "happy",
    4: "sad",
    5: "surprise",
    6: "neutral"
}
# åå‘æ˜ å°„ï¼ˆæ–¹ä¾¿æ‰“å°ï¼‰
IDX_TO_EMOTION = {v: k for k, v in EMOTION_MAP.items()}

# ===================== æ•°æ®å˜æ¢ï¼ˆå¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼ï¼‰ =====================
# æµ‹è¯•é›†å˜æ¢ï¼ˆå¦‚æœè®­ç»ƒæ—¶ç”¨äº†10-Cropï¼Œç”¨è¿™ä¸ªç‰ˆæœ¬ï¼‰
# test_transform = transforms.Compose([
#     transforms.TenCrop(44),  # å’Œè®­ç»ƒæ—¶çš„CenterCrop(44)åŒ¹é…
#     transforms.Lambda(lambda crops: torch.stack([
#         transforms.Compose([
#             transforms.ToTensor(),
#             # è®­ç»ƒæ—¶å¦‚æœåŠ äº†æ ‡å‡†åŒ–ï¼Œè¿™é‡Œå¿…é¡»åŠ ï¼
#             transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
#         ])(crop) for crop in crops
#     ])),
# ])

# å¦‚æœä½ è®­ç»ƒæ—¶æ²¡ç”¨åˆ°10-Cropï¼Œç”¨è¿™ä¸ªåŸºç¡€ç‰ˆæœ¬ï¼š
test_transform = transforms.Compose([
    transforms.CenterCrop(44),
    transforms.ToTensor(),
    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ===================== åŠ è½½FER2013æ•°æ®é›† =====================
def load_fer_dataset():
    """åŠ è½½FER2013çš„train/testé›†"""
    # éªŒè¯h5æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(FER_H5_PATH):
        print(f"âŒ æ‰¾ä¸åˆ°FER2013æ•°æ®æ–‡ä»¶ï¼š{FER_H5_PATH}")
        exit(1)
    
    test_dataset = Fer2013(
        split=TEST_SPLIT,
        transform=test_transform
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=4,  # 4090é€‚é…ï¼šCPUæ ¸å¿ƒæ•°çš„1/2
        pin_memory=True,  # GPUæ•°æ®ä¼ è¾“åŠ é€Ÿ
        persistent_workers=True  # ä¿æŒæ•°æ®åŠ è½½è¿›ç¨‹
    )
    print(f"âœ… FER2013 {TEST_SPLIT}é›†åŠ è½½å®Œæˆï¼Œå…±{len(test_dataset)}ä¸ªæ ·æœ¬")
    print(f"   - è®­ç»ƒé›†ï¼š28709æ ·æœ¬ | æµ‹è¯•é›†ï¼š7178æ ·æœ¬ï¼ˆå’Œä½ çš„h5ç»“æ„ä¸€è‡´ï¼‰")
    return test_loader

# ===================== åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ =====================
def load_model():
    """åŠ è½½ResNet18/VGG19æ¨¡å‹ï¼ŒåŠ è½½è®­ç»ƒæƒé‡"""
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆå’Œè®­ç»ƒæ—¶çš„ç»“æ„å®Œå…¨ä¸€è‡´ï¼ï¼‰
    # model = ResNet18(num_classes=NUM_CLASSES).to(DEVICE)
    # å¦‚æœæµ‹è¯•VGG19ï¼Œæ›¿æ¢ä¸ºï¼š
    model = VGG19(num_classes=NUM_CLASSES).to(DEVICE)
    
    # åŠ è½½æƒé‡ï¼ˆé€‚é…GPU/CPUï¼‰
    try:
        weight_dict = torch.load(MODEL_WEIGHT_PATH, map_location=DEVICE)
        model.load_state_dict(weight_dict)
        print(f"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼š{MODEL_WEIGHT_PATH}")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥ï¼š{e}")
        print("è¯·æ£€æŸ¥ï¼š1.æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡® 2.æ¨¡å‹ç»“æ„æ˜¯å¦å’Œè®­ç»ƒæ—¶ä¸€è‡´ï¼ˆæ¯”å¦‚Dropoutï¼‰")
        exit(1)
    
    # åˆ‡æ¢åˆ°é¢„æµ‹æ¨¡å¼ï¼ˆå…³é—­Dropout/BatchNormè®­ç»ƒè¡Œä¸ºï¼‰
    model.eval()
    return model

# ===================== æ‰§è¡Œé¢„æµ‹å¹¶è®¡ç®—æŒ‡æ ‡ =====================
def predict_on_fer(model, test_loader):
    """åœ¨FER2013ä¸Šæ‰§è¡Œé¢„æµ‹ï¼Œè®¡ç®—æ•´ä½“/æ¯ç±»å‡†ç¡®ç‡"""
    criterion = nn.CrossEntropyLoss()  # è®¡ç®—æŸå¤±ï¼ˆå¯é€‰ï¼‰
    total_loss = 0.0
    correct = 0
    total = 0
    
    # ç»Ÿè®¡æ¯ç±»çš„æ­£ç¡®æ•°/æ€»æ•°ï¼ˆåŒ¹é…EMOTION_MAPï¼‰
    class_correct = np.zeros(NUM_CLASSES, dtype=int)
    class_total = np.zeros(NUM_CLASSES, dtype=int)

    print(f"\nå¼€å§‹åœ¨FER2013 {TEST_SPLIT}é›†ä¸Šé¢„æµ‹...")
    with torch.no_grad():  # å…³é—­æ¢¯åº¦ï¼Œ4090æé€Ÿ+çœæ˜¾å­˜
        for batch_idx, (images, labels) in enumerate(test_loader):
            labels = labels.to(DEVICE)
            
            # å¤„ç†10-Cropæ•°æ®ï¼ˆå¦‚æœç”¨äº†10-Cropï¼‰
            if len(images.size()) == 5:  # (batch, 10, 3, 44, 44)
                bs, ncrops, c, h, w = images.size()
                images = images.view(-1, c, h, w).to(DEVICE)  # (batch*10, 3, 44, 44)
                
                # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­ï¼ˆ5090åŠ é€Ÿï¼‰
                with autocast():
                    outputs = model(images)
                    # 10-Cropå–å¹³å‡
                    outputs_avg = outputs.view(bs, ncrops, -1).mean(1)
                    loss = criterion(outputs_avg, labels)
                
                # ç»Ÿè®¡é¢„æµ‹ç»“æœ
                _, predicted = torch.max(outputs_avg, 1)
                batch_size_current = bs
            else:  # åŸºç¡€ç‰ˆæœ¬ï¼ˆæ— 10-Cropï¼‰
                images = images.to(DEVICE)
                
                with autocast():
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                
                _, predicted = torch.max(outputs, 1)
                batch_size_current = images.size(0)
            
            # ç»Ÿè®¡æ•´ä½“æŸå¤±å’Œå‡†ç¡®ç‡
            total_loss += loss.item() * batch_size_current
            total += batch_size_current
            correct += predicted.eq(labels).sum().item()
            
            # ç»Ÿè®¡æ¯ç±»çš„æ­£ç¡®æ•°/æ€»æ•°
            for i in range(batch_size_current):
                label = labels[i].item()
                class_total[label] += 1
                if predicted[i].item() == label:
                    class_correct[label] += 1
            
            # æ‰“å°æ‰¹æ¬¡è¿›åº¦
            if (batch_idx + 1) % 20 == 0:
                batch_acc = 100. * predicted.eq(labels).sum().item() / batch_size_current
                print(f"æ‰¹æ¬¡ [{batch_idx+1}/{len(test_loader)}] | æ‰¹æ¬¡æŸå¤±ï¼š{loss.item():.4f} | æ‰¹æ¬¡å‡†ç¡®ç‡ï¼š{batch_acc:.2f}%")

    # è®¡ç®—æ•´ä½“æŒ‡æ ‡
    avg_loss = total_loss / total
    overall_acc = 100. * correct / total

    # æ‰“å°ç»“æœ
    print("\n" + "="*70)
    print(f"ğŸ“Š FER2013 {TEST_SPLIT}é›†é¢„æµ‹ç»“æœï¼ˆResNet18ï¼‰")
    print(f"="*70)
    print(f"æ•´ä½“å¹³å‡æŸå¤±ï¼š{avg_loss:.4f}")
    print(f"æ•´ä½“å‡†ç¡®ç‡ï¼š{overall_acc:.2f}% ({correct}/{total})")
    print(f"="*70)

    # æ‰“å°æ¯ç±»è¡¨æƒ…å‡†ç¡®ç‡ï¼ˆæ ¸å¿ƒåˆ†ææ¨¡å‹è¡¨ç°ï¼‰
    print("\nğŸ¯ æ¯ç±»è¡¨æƒ…å‡†ç¡®ç‡ï¼š")
    print("-"*60)
    print(f"{'è¡¨æƒ…ç±»åˆ«':<10} {'ç´¢å¼•':<5} {'å‡†ç¡®ç‡':<10} {'æ­£ç¡®æ•°/æ€»æ•°'}")
    print("-"*60)
    for idx in range(NUM_CLASSES):
        if class_total[idx] > 0:
            class_acc = 100. * class_correct[idx] / class_total[idx]
            print(f"{EMOTION_MAP[idx]:<10} {idx:<5} {class_acc:.2f}%       {class_correct[idx]}/{class_total[idx]}")
        else:
            print(f"{EMOTION_MAP[idx]:<10} {idx:<5} æ— æ ·æœ¬         0/0")
    print("-"*60)

    # æ¨¡å‹è¡¨ç°åˆ†æ
    print("\nğŸ“ˆ æ¨¡å‹è¡¨ç°åˆ†æï¼š")
    if TEST_SPLIT == "train":
        if overall_acc > 90:
            print(f"- æ‹Ÿåˆèƒ½åŠ›ï¼šä¼˜ç§€ï¼ˆè®­ç»ƒé›†å‡†ç¡®ç‡>90%ï¼Œæ¨¡å‹å­¦åˆ°äº†ç‰¹å¾ï¼‰")
        elif overall_acc > 80:
            print(f"- æ‹Ÿåˆèƒ½åŠ›ï¼šä¸­ç­‰ï¼ˆè®­ç»ƒé›†å‡†ç¡®ç‡80%-90%ï¼Œæ‹Ÿåˆä¸å……åˆ†ï¼‰")
        else:
            print(f"- æ‹Ÿåˆèƒ½åŠ›ï¼šè¾ƒå·®ï¼ˆè®­ç»ƒé›†å‡†ç¡®ç‡<80%ï¼Œæ¨¡å‹æœªå­¦åˆ°æ ¸å¿ƒç‰¹å¾ï¼‰")
    else:  # testé›†
        if overall_acc > 70:
            print(f"- æ³›åŒ–èƒ½åŠ›ï¼šä¼˜ç§€ï¼ˆæµ‹è¯•é›†å‡†ç¡®ç‡>70%ï¼Œè·¨æ ·æœ¬æ³›åŒ–å¥½ï¼‰")
        elif overall_acc > 65:
            print(f"- æ³›åŒ–èƒ½åŠ›ï¼šä¸­ç­‰ï¼ˆæµ‹è¯•é›†å‡†ç¡®ç‡65%-70%ï¼Œè½»å¾®è¿‡æ‹Ÿåˆï¼‰")
        else:
            print(f"- æ³›åŒ–èƒ½åŠ›ï¼šè¾ƒå·®ï¼ˆæµ‹è¯•é›†å‡†ç¡®ç‡<65%ï¼Œä¸¥é‡è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆï¼‰")

# ===================== ä¸»å‡½æ•° =====================
if __name__ == "__main__":
    # 5090 GPUåŠ é€Ÿé…ç½®
    cudnn.benchmark = True
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡ï¼š{DEVICE}")
    if torch.cuda.is_available():
        print(f"ğŸ”§ GPUå‹å·ï¼š{torch.cuda.get_device_name(0)}")
        print(f"ğŸ”§ GPUæ˜¾å­˜ï¼š{torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    # 1. åŠ è½½æ¨¡å‹
    model = load_model()
    
    # 2. åŠ è½½FER2013æ•°æ®é›†
    test_loader = load_fer_dataset()
    
    # 3. æ‰§è¡Œé¢„æµ‹
    predict_on_fer(model, test_loader)